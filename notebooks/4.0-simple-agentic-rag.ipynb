{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Simple Agentic RAG from Scratch\n",
    "\n",
    "In this notebook, we'll build a simple agentic RAG system from scratch using:\n",
    "- **Ollama** for local LLM inference\n",
    "- **Tool calling** to give the agent capabilities\n",
    "- **ReAct loop** for reasoning and acting until task completion\n",
    "\n",
    "## What is ReAct?\n",
    "\n",
    "ReAct (Reasoning + Acting) is a pattern where:\n",
    "1. Agent **thinks** about what to do next\n",
    "2. Agent **acts** by calling a tool\n",
    "3. Agent **observes** the result\n",
    "4. Repeat until task is complete\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "User Query ‚Üí Agent (LLM) ‚Üí Tool Call ‚Üí Tool Execution ‚Üí Back to Agent ‚Üí Final Answer\n",
    "              ‚Üë                                            |\n",
    "              |______________ ReAct Loop _________________|\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama pypdf2 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-section",
   "metadata": {},
   "source": [
    "## Step 1: Build the Tools\n",
    "\n",
    "We'll create simple tools for working with PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tool-find-pdfs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pdf_files(directory=\"./assets-resources/pdfs\"):\n",
    "    \"\"\"\n",
    "    Find all PDF files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory: Path to search for PDFs\n",
    "\n",
    "    Returns:\n",
    "        String with newline-separated list of PDF file paths\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_files = glob.glob(f\"{directory}/**/*.pdf\", recursive=True)\n",
    "        if not pdf_files:\n",
    "            return f\"No PDF files found in {directory}\"\n",
    "        return \"\\n\".join(pdf_files)\n",
    "    except Exception as e:\n",
    "        return f\"Error finding PDF files: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tool-search-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pdf(pdf_path, search_pattern, context_lines=3):\n",
    "    \"\"\"\n",
    "    Search for a pattern in a PDF by first converting it to text, then searching.\n",
    "    \n",
    "    This function combines pdf_to_text and search_in_text into one simple tool.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        search_pattern: The text pattern to search for\n",
    "        context_lines: Number of lines of context to show around matches (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        String with search results and context, or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Convert PDF to text\n",
    "        output_dir = \"text_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        text_file_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "        \n",
    "        # Convert PDF to text using pdftotext\n",
    "        result = subprocess.run(\n",
    "            [\"pdftotext\", \"-layout\", pdf_path, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        \n",
    "        # Step 2: Search in the converted text file\n",
    "        search_result = subprocess.run(\n",
    "            [\"grep\", \"-i\", \"-C\", str(context_lines), search_pattern, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if search_result.returncode == 0:\n",
    "            return f\"Found matches for '{search_pattern}' in {pdf_path}:\\n\\n{search_result.stdout}\"\n",
    "        elif search_result.returncode == 1:\n",
    "            return f\"No matches found for '{search_pattern}' in {pdf_path}\"\n",
    "        else:\n",
    "            return f\"Error searching: {search_result.stderr}\"\n",
    "            \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error converting PDF: {e.stderr}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: pdftotext not found. Please install poppler-utils (brew install poppler on Mac)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "\n",
    "def read_full_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file to text using pdftotext and return the full text content.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        The full text content of the PDF, or an error message\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "    try:\n",
    "        output_dir = \"text_files\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "        text_file_path = os.path.join(output_dir, f\"{base_name}.txt\")\n",
    "\n",
    "        # Convert PDF to text using pdftotext\n",
    "        subprocess.run(\n",
    "            [\"pdftotext\", \"-layout\", pdf_path, text_file_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Read and return the contents of the resulting text file\n",
    "        with open(text_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            return f.read()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        return f\"Error converting PDF: {e.stderr}\"\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: pdftotext not found. Please install poppler-utils (brew install poppler on Mac)\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tool-read-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path, num_lines=None):\n",
    "    \"\"\"\n",
    "    Read and return the content of a text file.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the text file\n",
    "        num_lines: Optional number of lines to read from the beginning\n",
    "\n",
    "    Returns:\n",
    "        The file content or error message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if num_lines:\n",
    "            result = subprocess.run(\n",
    "                [\"head\", \"-n\", str(num_lines), file_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True\n",
    "            )\n",
    "            return result.stdout\n",
    "        else:\n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                return f.read()\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-tools",
   "metadata": {},
   "source": [
    "### Test the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "test-tools-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDFs:\n",
      "./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n"
     ]
    }
   ],
   "source": [
    "# Test: Find PDFs\n",
    "pdfs = find_pdf_files()\n",
    "print(f\"Found PDFs:\")\n",
    "print(pdfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-section",
   "metadata": {},
   "source": [
    "## Step 2: Define Tool Schemas for Ollama\n",
    "\n",
    "We need to define the tools in a format that Ollama understands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tool-schemas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool schemas created successfully!\n",
      "Available tools: find_pdf_files, search_pdf, read_full_pdf\n"
     ]
    }
   ],
   "source": [
    "TOOLS = [\n",
    "    { \n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'find_pdf_files',\n",
    "            'description': 'Finds all PDF files in the specified directory and subdirectories. Use this first to discover what PDFs are available.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': { \n",
    "                    'directory': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The directory path to search for PDF files (default: ./assets-resources/pdfs)'\n",
    "                    }\n",
    "                },\n",
    "                'required': []\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'search_pdf',\n",
    "            'description': 'Search for a keyword or phrase in a PDF file. This tool automatically converts the PDF to text and searches it. Returns matching excerpts with context.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'pdf_path': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Path to the PDF file to search'\n",
    "                    },\n",
    "                    'search_pattern': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'The keyword or phrase to search for'\n",
    "                    },\n",
    "                    'context_lines': {\n",
    "                        'type': 'integer',\n",
    "                        'description': 'Number of lines of context to show around matches (default: 3)'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['pdf_path', 'search_pattern']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'type': 'function',\n",
    "        'function': {\n",
    "            'name': 'read_full_pdf',\n",
    "            'description': 'Read the full text content of a PDF file.',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'pdf_path': {\n",
    "                        'type': 'string',\n",
    "                        'description': 'Path to the PDF file'\n",
    "                    }\n",
    "                },\n",
    "                'required': ['pdf_path']\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "]\n",
    "\n",
    "print(\"Tool schemas created successfully!\")\n",
    "print(f\"Available tools: {', '.join([tool['function']['name'] for tool in TOOLS])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-class",
   "metadata": {},
   "source": [
    "## Step 3: Build the Simple ReAct Agent\n",
    "\n",
    "Now we'll create a simple agent class that implements the ReAct loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "agent-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SimpleAgent:\n",
    "    def __init__(self, model=\"mistral-small3.2\", max_turns=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize a simple ReAct agent.\n",
    "        \n",
    "        Args:\n",
    "            model: Ollama model to use\n",
    "            max_turns: Maximum number of reasoning-action turns\n",
    "            verbose: Whether to print agent's reasoning process\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.max_turns = max_turns\n",
    "        self.verbose = verbose\n",
    "        self.tools_map = {\n",
    "            'find_pdf_files': find_pdf_files,\n",
    "            'search_pdf': search_pdf,\n",
    "            'read_text_file': read_text_file\n",
    "        }\n",
    "        \n",
    "    def execute_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:\n",
    "        \"\"\"Execute a tool and return its result.\"\"\"\n",
    "        if tool_name not in self.tools_map:\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "        \n",
    "        try:\n",
    "            result = self.tools_map[tool_name](**arguments)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Error executing {tool_name}: {str(e)}\"\n",
    "    \n",
    "    def run(self, user_query: str) -> str:\n",
    "        \"\"\"\n",
    "        Run the agent with a user query using the ReAct loop.\n",
    "        \n",
    "        Args:\n",
    "            user_query: The user's question or task\n",
    "        \n",
    "        Returns:\n",
    "            Final answer from the agent\n",
    "        \"\"\"\n",
    "        # Initialize conversation history\n",
    "        messages = [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are a helpful assistant that can search through PDF documents to answer questions.\n",
    "\n",
    "Use the available tools to:\n",
    "1. First, find what PDFs are available using find_pdf_files(directory=\"./assets-resources/pdfs\")\n",
    "2. Search for relevant keywords in PDFs using search_pdf(pdf_path, search_pattern, context_lines=3)\n",
    "3. Read the full text content of a PDF file using read_full_pdf(pdf_path) when you need to read the entire content of a PDF file to answer the question.\n",
    "\n",
    "Think carefully and use tools as needed. \n",
    "When you have enough information to answer the user's question, provide a clear final answer.\n",
    "'''\n",
    "            },\n",
    "            {'role': 'user', 'content': user_query}\n",
    "        ]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"User Query: {user_query}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # ReAct loop\n",
    "        for turn in range(self.max_turns):\n",
    "            if self.verbose:\n",
    "                print(f\"\\n--- Turn {turn + 1}/{self.max_turns} ---\")\n",
    "            \n",
    "            # Get response from LLM\n",
    "            response = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=TOOLS\n",
    "            )\n",
    "            \n",
    "            assistant_message = response['message']\n",
    "            \n",
    "            # Check if agent wants to call a tool\n",
    "            if 'tool_calls' in assistant_message and assistant_message['tool_calls']:\n",
    "                # Add assistant's tool call to history\n",
    "                messages.append(assistant_message)\n",
    "                \n",
    "                # Execute each tool call\n",
    "                for tool_call in assistant_message['tool_calls']:\n",
    "                    tool_name = tool_call['function']['name']\n",
    "                    arguments = tool_call['function']['arguments']\n",
    "                    \n",
    "                    if self.verbose:\n",
    "                        print(f\"\\nüîß Tool Call: {tool_name}\")\n",
    "                        print(f\"   Arguments: {arguments}\")\n",
    "                    \n",
    "                    # Execute the tool\n",
    "                    tool_result = self.execute_tool(tool_name, arguments)\n",
    "                    \n",
    "                    if self.verbose:\n",
    "                        print(f\"   Result: {tool_result[:200]}...\" if len(tool_result) > 200 else f\"   Result: {tool_result}\")\n",
    "                    \n",
    "                    # Add tool result to messages\n",
    "                    messages.append({\n",
    "                        'role': 'tool',\n",
    "                        'content': tool_result\n",
    "                    })\n",
    "            \n",
    "            # Check if agent provided a final answer (no tool calls)\n",
    "            elif 'content' in assistant_message:\n",
    "                final_answer = assistant_message['content']\n",
    "                \n",
    "                if self.verbose:\n",
    "                    print(f\"\\n‚úÖ Final Answer (after {turn + 1} turns):\")\n",
    "                    print(f\"\\n{final_answer}\")\n",
    "                    print(f\"\\n{'='*60}\\n\")\n",
    "                \n",
    "                return final_answer\n",
    "        \n",
    "        # Max turns reached\n",
    "        return \"Max turns reached. Unable to complete the task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-section",
   "metadata": {},
   "source": [
    "## Step 4: Use the Agent\n",
    "\n",
    "Let's create an agent and test it with some questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "create-agent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "agent = SimpleAgent(\n",
    "    model=\"mistral-small3.2\",\n",
    "    max_turns=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-1",
   "metadata": {},
   "source": [
    "### Example 1: Simple Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "example-1-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: What PDFs are available and what topics do they cover?\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "üîß Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "‚úÖ Final Answer (after 2 turns):\n",
      "\n",
      "Here are the available PDFs and their topics:\n",
      "\n",
      "1. **instruction-tune-llama2-extended-guide.pdf**: This document likely covers an extended guide on instruction tuning for Llama 2, a large language model.\n",
      "2. **lora-paper.pdf**: This PDF is probably a research paper discussing LoRA (Low-Rank Adaptation), a technique used in machine learning for efficient model fine-tuning.\n",
      "3. **sparks-agi-paper.pdf**: This document is likely a research paper exploring the concept of Artificial General Intelligence (AGI) and its implications.\n",
      "4. **qlora-paper.pdf**: This PDF is probably a research paper discussing QLoRA (Quantized Low-Rank Adaptation), a technique that combines quantization and low-rank adaptation for efficient model fine-tuning.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Final Answer:\n",
      "Here are the available PDFs and their topics:\n",
      "\n",
      "1. **instruction-tune-llama2-extended-guide.pdf**: This document likely covers an extended guide on instruction tuning for Llama 2, a large language model.\n",
      "2. **lora-paper.pdf**: This PDF is probably a research paper discussing LoRA (Low-Rank Adaptation), a technique used in machine learning for efficient model fine-tuning.\n",
      "3. **sparks-agi-paper.pdf**: This document is likely a research paper exploring the concept of Artificial General Intelligence (AGI) and its implications.\n",
      "4. **qlora-paper.pdf**: This PDF is probably a research paper discussing QLoRA (Quantized Low-Rank Adaptation), a technique that combines quantization and low-rank adaptation for efficient model fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\"What PDFs are available and what topics do they cover?\")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-2",
   "metadata": {},
   "source": [
    "### Example 2: Search for Specific Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "example-2-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: What is the lora technique?\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "üîß Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "üîß Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'lora technique'}\n",
      "   Result: No matches found for 'lora technique' in ./assets-resources/pdfs/lora-paper.pdf\n",
      "\n",
      "--- Turn 3/10 ---\n",
      "\n",
      "üîß Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'lora'}\n",
      "   Result: Found matches for 'lora' in ./assets-resources/pdfs/lora-paper.pdf:\n",
      "\n",
      "                                                   we pre-train larger models, full fine-tuning, which retrains all model parameter...\n",
      "\n",
      "--- Turn 4/10 ---\n",
      "\n",
      "‚úÖ Final Answer (after 4 turns):\n",
      "\n",
      "The provided text discusses various adaptation methods for large language models like GPT-2 and GPT-3, focusing on techniques such as fine-tuning, prefix-based methods (PrefixEmbed and PrefixLayer), and LoRA (Low-Rank Adaptation). Here's a summary of the key points:\n",
      "\n",
      "### Adaptation Methods\n",
      "1. **Fine-Tuning**:\n",
      "   - Involves updating all parameters of the model.\n",
      "   - Effective but computationally expensive and memory-intensive.\n",
      "\n",
      "2. **Prefix-Based Methods**:\n",
      "   - **PrefixEmbed**: Adds trainable embeddings at the beginning of the input sequence.\n",
      "   - **PrefixLayer**: Adds trainable layers before the original model layers.\n",
      "   - Generally perform worse than fine-tuning and LoRA, especially in low-data scenarios.\n",
      "\n",
      "3. **LoRA (Low-Rank Adaptation)**:\n",
      "   - Introduces low-rank matrices to freeze the pre-trained model weights and only train these low-rank matrices.\n",
      "   - More parameter-efficient and effective, especially for large models like GPT-3.\n",
      "\n",
      "### Performance Comparison\n",
      "- **DART and WebNLG Tasks**:\n",
      "  - LoRA outperforms or matches fine-tuning and other adaptation methods.\n",
      "  - Prefix-based methods show poorer performance, particularly in low-data settings.\n",
      "\n",
      "- **MNLI-n Tasks**:\n",
      "  - LoRA exhibits favorable sample efficiency, performing better than prefix-based methods and comparably to fine-tuning.\n",
      "  - PrefixEmbed and PrefixLayer perform poorly on low-data tasks but improve with more training examples.\n",
      "\n",
      "### Hyperparameter Analysis\n",
      "- **LoRA Rank (r)**:\n",
      "  - The optimal rank varies by task and model. For GPT-2 Medium, performance peaks at different ranks for different metrics (e.g., r=16 for validation loss, r=4 for BLEU).\n",
      "  - For GPT-3, a rank of r=1 often suffices for many tasks.\n",
      "\n",
      "- **Learning Rates**:\n",
      "  - Different methods require different learning rates. For example, PrefixLayer typically uses a lower learning rate (e.g., 5.00E-05) compared to PrefixEmbed (e.g., 2.00E-04).\n",
      "\n",
      "### Key Findings\n",
      "- **Efficiency**: LoRA is more parameter-efficient and effective for adapting large language models.\n",
      "- **Scalability**: Prefix-based methods scale poorly with the number of trainable parameters, while LoRA's performance stabilizes.\n",
      "- **Sample Efficiency**: LoRA shows better performance in low-data scenarios compared to prefix-based methods.\n",
      "\n",
      "### Conclusion\n",
      "LoRA is a promising adaptation method for large language models, offering a balance between performance and efficiency. It outperforms or matches fine-tuning and prefix-based methods in various tasks and settings, making it a suitable choice for adapting large models like GPT-3.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Final Answer:\n",
      "The provided text discusses various adaptation methods for large language models like GPT-2 and GPT-3, focusing on techniques such as fine-tuning, prefix-based methods (PrefixEmbed and PrefixLayer), and LoRA (Low-Rank Adaptation). Here's a summary of the key points:\n",
      "\n",
      "### Adaptation Methods\n",
      "1. **Fine-Tuning**:\n",
      "   - Involves updating all parameters of the model.\n",
      "   - Effective but computationally expensive and memory-intensive.\n",
      "\n",
      "2. **Prefix-Based Methods**:\n",
      "   - **PrefixEmbed**: Adds trainable embeddings at the beginning of the input sequence.\n",
      "   - **PrefixLayer**: Adds trainable layers before the original model layers.\n",
      "   - Generally perform worse than fine-tuning and LoRA, especially in low-data scenarios.\n",
      "\n",
      "3. **LoRA (Low-Rank Adaptation)**:\n",
      "   - Introduces low-rank matrices to freeze the pre-trained model weights and only train these low-rank matrices.\n",
      "   - More parameter-efficient and effective, especially for large models like GPT-3.\n",
      "\n",
      "### Performance Comparison\n",
      "- **DART and WebNLG Tasks**:\n",
      "  - LoRA outperforms or matches fine-tuning and other adaptation methods.\n",
      "  - Prefix-based methods show poorer performance, particularly in low-data settings.\n",
      "\n",
      "- **MNLI-n Tasks**:\n",
      "  - LoRA exhibits favorable sample efficiency, performing better than prefix-based methods and comparably to fine-tuning.\n",
      "  - PrefixEmbed and PrefixLayer perform poorly on low-data tasks but improve with more training examples.\n",
      "\n",
      "### Hyperparameter Analysis\n",
      "- **LoRA Rank (r)**:\n",
      "  - The optimal rank varies by task and model. For GPT-2 Medium, performance peaks at different ranks for different metrics (e.g., r=16 for validation loss, r=4 for BLEU).\n",
      "  - For GPT-3, a rank of r=1 often suffices for many tasks.\n",
      "\n",
      "- **Learning Rates**:\n",
      "  - Different methods require different learning rates. For example, PrefixLayer typically uses a lower learning rate (e.g., 5.00E-05) compared to PrefixEmbed (e.g., 2.00E-04).\n",
      "\n",
      "### Key Findings\n",
      "- **Efficiency**: LoRA is more parameter-efficient and effective for adapting large language models.\n",
      "- **Scalability**: Prefix-based methods scale poorly with the number of trainable parameters, while LoRA's performance stabilizes.\n",
      "- **Sample Efficiency**: LoRA shows better performance in low-data scenarios compared to prefix-based methods.\n",
      "\n",
      "### Conclusion\n",
      "LoRA is a promising adaptation method for large language models, offering a balance between performance and efficiency. It outperforms or matches fine-tuning and prefix-based methods in various tasks and settings, making it a suitable choice for adapting large models like GPT-3.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\"What is the lora technique?\")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-3",
   "metadata": {},
   "source": [
    "### Example 3: Multi-Step Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-3-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: Summarize in one sentence each of the pdfs.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Turn 1/10 ---\n",
      "\n",
      "üîß Tool Call: find_pdf_files\n",
      "   Arguments: {'directory': './assets-resources/pdfs'}\n",
      "   Result: ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf\n",
      "./assets-resources/pdfs/lora-paper.pdf\n",
      "./assets-resources/pdfs/sparks-agi-paper.pdf\n",
      "./assets-resources/pdfs/qlora-paper.pdf\n",
      "\n",
      "--- Turn 2/10 ---\n",
      "\n",
      "üîß Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf', 'search_pattern': 'summary'}\n",
      "   Result: Found matches for 'summary' in ./assets-resources/pdfs/instruction-tune-llama2-extended-guide.pdf:\n",
      "\n",
      "                                                                        cream.\n",
      "\n",
      "                    ...\n",
      "\n",
      "--- Turn 3/10 ---\n",
      "\n",
      "üîß Tool Call: search_pdf\n",
      "   Arguments: {'pdf_path': './assets-resources/pdfs/lora-paper.pdf', 'search_pattern': 'summary'}\n",
      "   Result: Found matches for 'summary' in ./assets-resources/pdfs/lora-paper.pdf:\n",
      "\n",
      "reading comprehension (MRC), and natural language to SQL (NL2SQL). Each downstream task is\n",
      "represented by a training dataset of ...\n",
      "\n",
      "--- Turn 4/10 ---\n",
      "\n",
      "‚úÖ Final Answer (after 4 turns):\n",
      "\n",
      "The PDF \"lora-paper.pdf\" discusses the application of LoRA (Low-Rank Adaptation) in various natural language processing tasks, including summarization, and provides details about datasets like SAMSum and E2E NLG Challenge.\n",
      "\n",
      "I will now search for relevant keywords in the next PDF.\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "Final Answer:\n",
      "The PDF \"lora-paper.pdf\" discusses the application of LoRA (Low-Rank Adaptation) in various natural language processing tasks, including summarization, and provides details about datasets like SAMSum and E2E NLG Challenge.\n",
      "\n",
      "I will now search for relevant keywords in the next PDF.\n"
     ]
    }
   ],
   "source": [
    "answer = agent.run(\n",
    "    \"Summarize in one sentence each of the pdfs.\"\n",
    ")\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding",
   "metadata": {},
   "source": [
    "## Understanding the ReAct Loop\n",
    "\n",
    "Let's break down what happens in each turn:\n",
    "\n",
    "1. **Turn 1**: Agent receives user query, decides to call `find_pdfs` to discover available documents\n",
    "2. **Turn 2**: Agent receives list of PDFs, decides to call `search_pdf` with a relevant keyword\n",
    "3. **Turn 3**: Agent receives search results, may search more PDFs or read specific pages\n",
    "4. **Turn N**: Agent has enough information, provides final answer\n",
    "\n",
    "The agent autonomously decides:\n",
    "- Which tools to use\n",
    "- What arguments to pass\n",
    "- When it has enough information to answer\n",
    "\n",
    "This is the power of agentic systems!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "customization",
   "metadata": {},
   "source": [
    "## Customization Tips\n",
    "\n",
    "You can easily extend this agent by:\n",
    "\n",
    "1. **Adding more tools**: Create new functions and add them to `TOOLS` and `tools_map`\n",
    "2. **Changing the model**: Use different Ollama models like `qwen3`, etc.\n",
    "3. **Adjusting max_turns**: Control how many reasoning steps the agent can take\n",
    "4. **Modifying the system prompt**: Change the agent's behavior and personality\n",
    "5. **Adding memory**: Store conversation history across multiple runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "## Comparison: Simple Agent vs Framework\n",
    "\n",
    "**Our Simple Agent (~100 lines):**\n",
    "- ‚úÖ Full control over every step\n",
    "- ‚úÖ Easy to understand and debug\n",
    "- ‚úÖ No external dependencies (just Ollama)\n",
    "- ‚úÖ Perfect for learning and teaching\n",
    "- ‚ùå Limited features\n",
    "- ‚ùå Manual tool integration\n",
    "\n",
    "**Framework (e.g., SmoLAgents, LangChain):**\n",
    "- ‚úÖ Many built-in tools and features\n",
    "- ‚úÖ Production-ready\n",
    "- ‚úÖ Advanced capabilities (memory, planning, etc.)\n",
    "- ‚ùå Steeper learning curve\n",
    "- ‚ùå Abstractions can hide important details\n",
    "- ‚ùå Additional dependencies\n",
    "\n",
    "**When to use each:**\n",
    "- Use simple agent: Learning, prototyping, simple tasks, full control\n",
    "- Use framework: Production systems, complex workflows, team projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these challenges to deepen your understanding:\n",
    "\n",
    "1. **Add a new tool** that can extract metadata from PDFs (author, title, creation date)\n",
    "2. **Modify the system prompt** to make the agent more concise or more detailed\n",
    "3. **Add conversation memory** so the agent remembers previous queries\n",
    "4. **Create a comparison tool** that can search multiple PDFs and compare results\n",
    "5. **Add error handling** to gracefully handle missing PDFs or invalid queries\n",
    "6. **Implement streaming** to show the agent's reasoning in real-time\n",
    "7. **Add a summarization tool** that can summarize entire PDFs or sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've built a simple but powerful agentic RAG system from scratch! Key takeaways:\n",
    "\n",
    "1. **ReAct Loop**: The pattern of Reason ‚Üí Act ‚Üí Observe is fundamental to agents\n",
    "2. **Tool Calling**: LLMs can decide which tools to use and when\n",
    "3. **Local Models**: Ollama makes it easy to run agents completely locally\n",
    "4. **Simplicity**: You don't need complex frameworks to build useful agents\n",
    "\n",
    "This foundational understanding will help you work with any agent framework and build more sophisticated systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
