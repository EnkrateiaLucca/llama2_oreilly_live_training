{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37f7184",
   "metadata": {},
   "source": [
    "# Run a local llm with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a39c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1218a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to our course, \"Getting Started with Llama 3,\" where we'll explore the capabilities and best practices of working with Amazon's conversational AI model, Llama 3!\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Say hello to my students for the course: \"Getting Started with Llama 3\". One single sentence.',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model='gemma3n', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Say hello to my students for the course: \"Getting Started with Llama 3\". One single sentence.',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4eef295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                     ID              SIZE      MODIFIED      \n",
      "gemma3n:latest                           15cb39fd9394    7.5 GB    3 weeks ago      \n",
      "mistral-small3.2:latest                  5a408ab55df5    15 GB     4 weeks ago      \n",
      "llama3.2-vision:11b                      6f2f9757ae97    7.8 GB    5 weeks ago      \n",
      "llava:latest                             8dd30f6b0cb1    4.7 GB    5 weeks ago      \n",
      "qwen3:8b                                 500a1f067a9f    5.2 GB    6 weeks ago      \n",
      "snowflake-arctic-embed:xs                dfbdc120552e    45 MB     6 weeks ago      \n",
      "phi4:latest                              ac896e5b8b34    9.1 GB    6 weeks ago      \n",
      "qwen2.5vl:latest                         5ced39dfa4ba    6.0 GB    7 weeks ago      \n",
      "qwen3:4b                                 2bfd38a7daaf    2.6 GB    8 weeks ago      \n",
      "Osmosis/Osmosis-Structure-0.6B:latest    f24ec096ac55    1.2 GB    2 months ago     \n",
      "qwen3:32b                                e1c9f234c6eb    20 GB     2 months ago     \n",
      "qwen3:latest                             e4b5fd7f8af0    5.2 GB    2 months ago     \n",
      "gemma3:27b                               a418f5838eaf    17 GB     3 months ago     \n",
      "gemma3:latest                            a2af6cc3eb7f    3.3 GB    3 months ago     \n",
      "qwq:latest                               cc1091b0e276    19 GB     4 months ago     \n",
      "mxbai-embed-large:latest                 468836162de7    669 MB    5 months ago     \n",
      "deepseek-r1:14b                          ea35dfe18182    9.0 GB    6 months ago     \n",
      "deepseek-r1:latest                       0a8c26691023    4.7 GB    6 months ago     \n",
      "llama3.3:latest                          a6eb4748fd29    42 GB     7 months ago     \n",
      "llama3.2-vision:latest                   38107a0cd119    7.9 GB    8 months ago     \n",
      "llama3.2:latest                          a80c4f17acd5    2.0 GB    10 months ago    \n",
      "dolphin-llama3:latest                    613f068e29f8    4.7 GB    10 months ago    \n",
      "nomic-embed-text:latest                  0a109f422b47    274 MB    11 months ago    \n",
      "llama3.1:8b                              62757c860e01    4.7 GB    12 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8c3c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, everyone, to \"Getting Started with Llama 3\" – I'm excited to embark on this journey of exploring powerful language models with you!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Welcome, everyone, to \"Getting Started with Llama 3\" – I\\'m excited to embark on this journey of exploring powerful language models with you!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_llm_api_call(model_name, prompt):\n",
    "    response = ollama.chat(model='gemma3n', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Say hello to my students for the course: \"Getting Started with Llama 3\". One single sentence.',\n",
    "    },\n",
    "    ])\n",
    "    output = response['message']['content']\n",
    "    print(output)\n",
    "    \n",
    "    return output\n",
    "\n",
    "open_llm_api_call(\"gemma3n\", \"Say hello to my students for the course: 'Getting Started with Llama 3'. One single sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d43586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
