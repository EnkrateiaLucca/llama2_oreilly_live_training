{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12677baf",
   "metadata": {},
   "source": [
    "1. Input from user\n",
    "2. Local llm\n",
    "3. LLM provides structured output for a function to be called\n",
    "4. We call the function\n",
    "5. We take the output of the function and feed that back into the llm\n",
    "6. the llm provides an output for the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0a895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt_from_user = \"\"\"\n",
    "What is Lucas profession, favorite movie and favorite book??\n",
    "Use the information from the file: lucas_secrets.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ae3b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Lucas Soares\\nProfession: Software Engineer\\nFavorite Movie: Inception\\nFavorite Book: The Name of the Wind'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lucas_info(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()\n",
    "    \n",
    "get_lucas_info(file_path=\"./lucas_secrets.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b51c0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'function': {'name': 'get_lucas_info', 'arguments': {'file_path': 'lucas_secrets.txt'}}}]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='mistral-small3.2',\n",
    "    messages=[{'role': 'user', 'content': \n",
    "        input_prompt_from_user}],\n",
    "\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_lucas_info',\n",
    "        'description': 'Get the information about Lucas',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'file_path': {\n",
    "              'type': 'string',\n",
    "              'description': 'The path to the file containing the information about Lucas',\n",
    "            },\n",
    "          },\n",
    "          'required': ['file_path'],\n",
    "        },\n",
    "      },\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2b1af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: Lucas Soares\\nProfession: Software Engineer\\nFavorite Movie: Inception\\nFavorite Book: The Name of the Wind'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def execute_tool_call(tool_call_output):\n",
    "    if tool_call_output[0]['function']['name'] == 'get_lucas_info':\n",
    "        return get_lucas_info(tool_call_output[0]['function']['arguments']['file_path'])\n",
    "    else:\n",
    "        return \"Tool not found\"\n",
    "\n",
    "tool_call_output = response['message']['tool_calls']    \n",
    "output_of_function = execute_tool_call(tool_call_output)\n",
    "output_of_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8942d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'mistral-small3.2', 'created_at': '2025-10-03T16:54:29.574068Z', 'message': {'role': 'assistant', 'content': 'Based on the information from the file `lucas_secrets.txt`, here are the details about Lucas:\\n\\n- **Profession**: Software Engineer\\n- **Favorite Movie**: *Inception*\\n- **Favorite Book**: *The Name of the Wind*'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3948886791, 'load_duration': 67566291, 'prompt_eval_count': 579, 'prompt_eval_duration': 1046287750, 'eval_count': 52, 'eval_duration': 2833028167}\n"
     ]
    }
   ],
   "source": [
    "new_input_with_more_information = f\"\"\"\n",
    "The initial query was: {input_prompt_from_user}.\n",
    "The output of the function was: {output_of_function}.\n",
    "Provide the answer:\n",
    "\"\"\"\n",
    "response = ollama.chat(\n",
    "    model='mistral-small3.2',\n",
    "    messages=[{'role': 'user', 'content': \n",
    "        new_input_with_more_information}],\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cef69fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Name: Lucas Soares\n",
       "Profession: Software Engineer\n",
       "Favorite Movie: Inception\n",
       "Favorite Book: The Name of the Wind"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(f\"# {output_of_function}\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
